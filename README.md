# ğŸ“° ZMB Classifiers

**Pipeline modular para classificaÃ§Ã£o binÃ¡ria de matÃ©rias jornalÃ­sticas com referÃªncias raciais ou culturais (branca / negra / cultura negra).**

---

## ğŸ¯ Objetivo

Classificar textos jornalÃ­sticos como:

* **`0`** â€“ Sem referÃªncias a raÃ§a/cultura branca, raÃ§a/cultura negra ou cultura negra.
* **`1`** â€“ Com **pelo menos uma** referÃªncia a:

  * RaÃ§a branca (ex.: *"um homem branco"*, *"supremacia branca"*).
  * RaÃ§a negra (ex.: *"uma mulher negra"*, *"uma pessoa preta"*).
  * Cultura negra (ex.: *"capoeira"*, *"Lei Ãurea"*).

---

## ğŸ“¦ InstalaÃ§Ã£o

```bash
git clone git@github.com:Zumbi-ML/zmb-classifiers.git
cd zmb-classifiers
pip install .
```

### ğŸ“Œ DependÃªncia obrigatÃ³ria

Instale tambÃ©m o [zmb-newslink-extractor](https://github.com/seu_usuario/zmb-newslink-extractor), responsÃ¡vel pela extraÃ§Ã£o dos textos jornalÃ­sticos:

```bash
git clone git@github.com:Zumbi-ML/zmb-newslink-extractor.git
cd zmb-newslink-extractor
pip install .
```

---

## ğŸš© Pipeline de Uso

### 1. **PreparaÃ§Ã£o das URLs e Labels**

Crie um arquivo Excel em `data/01-newslinks-labelled/` com o seguinte formato:

| URL                          | label |
| ---------------------------- | ----- |
| `https://.../materia1.shtml` | 1     |
| `https://.../materia2.shtml` | 0     |

> âœ… Colunas obrigatÃ³rias: `URL` e `label`

---

### 2. **ExtraÃ§Ã£o dos Textos** (usando `zmb-newslink-extractor`)

```bash
zmb-extract \
  --file data/01-newslinks-labelled/seus_dados.xlsx \
  --sheet "Sheetname" \
  --label-column "label" \
  --export-path data/03-jsonified/ \
  --output materias_extraidas
```

**SaÃ­da:** Arquivos JSON em `data/03-jsonified/`, um por matÃ©ria.

**Exemplo de JSON:**

```json
[
  {
    "title": "TÃ­tulo da matÃ©ria",
    "source": "URL da matÃ©ria",
    "text": "Texto completo da matÃ©ria...",
    "interest": 1
  }
]
```

---

### 3. **GeraÃ§Ã£o do Dataset de Treinamento (CSV)**

```bash
zmb-clf make-dataset --config config.yaml
```

**SaÃ­da:** Um CSV consolidado em `data/04-ready_4_training/classifier_dataset.csv`.

---

### 4. **Treinamento do Modelo**

```bash
zmb-clf train --config config.yaml
```

**SaÃ­da:** Modelo salvo em `models/zmb_model/`.

---

### 5. **(Opcional) AvaliaÃ§Ã£o da Performance**

```bash
zmb-clf evaluate --config config.yaml
```

**SaÃ­da:** MÃ©tricas como precisÃ£o, recall e F1-score em `evaluation/resultados_avaliacao.csv`.

---

## ğŸ—‚ï¸ Estrutura do Projeto

```
zmb-classifiers/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ 01-newslinks-labelled/   # URLs + labels
â”‚   â”œâ”€â”€ 03-jsonified/            # MatÃ©rias extraÃ­das (JSON)
â”‚   â””â”€â”€ 04-ready_4_training/     # Dataset final (CSV)
â”œâ”€â”€ models/                      # Modelos treinados
â”œâ”€â”€ evaluation/                  # AvaliaÃ§Ãµes
â”œâ”€â”€ zmb/                         # CÃ³digo-fonte
â”œâ”€â”€ config.yaml                  # ConfiguraÃ§Ã£o
â”œâ”€â”€ requirements.txt             # DependÃªncias
â””â”€â”€ README.md                    # Este arquivo
```

---

## ğŸ”§ Exemplo de ConfiguraÃ§Ã£o (`config.yaml`)

```yaml
paths:
  raw_json_dir: "./data/03-jsonified"
  dataset_csv: "./data/04-ready_4_training/classifier_dataset.csv"
  model_output_dir: "./models/zmb_model"
  evaluation_results: "./evaluation/resultados_avaliacao.csv"

training:
  test_size: 0.2
  random_state: 42
```

---

## ğŸ“‹ Requisitos

* Python 3.7+
* transformers >= 4.46.0
* datasets >= 3.1.0
* torch >= 2.4.0
* pandas >= 2.0.0
* scikit-learn >= 1.3.0
* PyYAML >= 6.0
* tqdm
* psutil
* zmb-newslink-extractor (projeto separado)

> Instale as dependÃªncias com:

```bash
pip install -r requirements.txt
```

---

## ğŸ‘¨â€ğŸ’» Autor

Jefferson O. Silva â€“ [silvajo@pucsp.br](mailto:silvajo@pucsp.br)